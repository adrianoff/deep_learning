{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.datasets import mnist\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "# Преобразуем метки в категории\n",
    "Y_train = np_utils.to_categorical(Y_train, 10)\n",
    "Y_test = np_utils.to_categorical(Y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "# Нормализация данных\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(init):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_shape=(28*28,), kernel_initializer=init, activation='tanh'))\n",
    "    model.add(Dense(100, kernel_initializer=init, activation='tanh'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(100, kernel_initializer=init, activation='tanh'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, kernel_initializer=init, activation='tanh'))\n",
    "    model.add(Dense(10, kernel_initializer=init, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#niform_model = create_model(\"uniform\")\n",
    "uniform_model = create_model(\"glorot_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0055 - acc: 0.9982 - val_loss: 0.1635 - val_acc: 0.9758\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0056 - acc: 0.9984 - val_loss: 0.1499 - val_acc: 0.9776\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0051 - acc: 0.9983 - val_loss: 0.1490 - val_acc: 0.9784\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0068 - acc: 0.9981 - val_loss: 0.1458 - val_acc: 0.9789\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0050 - acc: 0.9986 - val_loss: 0.1577 - val_acc: 0.9772\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0040 - acc: 0.9988 - val_loss: 0.1504 - val_acc: 0.9783\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0070 - acc: 0.9980 - val_loss: 0.1743 - val_acc: 0.9744\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0065 - acc: 0.9980 - val_loss: 0.1526 - val_acc: 0.9768\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0083 - acc: 0.9976 - val_loss: 0.1682 - val_acc: 0.9734\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0051 - acc: 0.9984 - val_loss: 0.1457 - val_acc: 0.9777\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0037 - acc: 0.9989 - val_loss: 0.1630 - val_acc: 0.9759\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0036 - acc: 0.9989 - val_loss: 0.1703 - val_acc: 0.9752\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0072 - acc: 0.9977 - val_loss: 0.1662 - val_acc: 0.9758\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0058 - acc: 0.9983 - val_loss: 0.1710 - val_acc: 0.9749\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0041 - acc: 0.9985 - val_loss: 0.1612 - val_acc: 0.9761\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0050 - acc: 0.9984 - val_loss: 0.1521 - val_acc: 0.9775\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0080 - acc: 0.9975 - val_loss: 0.1583 - val_acc: 0.9772\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0039 - acc: 0.9987 - val_loss: 0.1565 - val_acc: 0.9773\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0053 - acc: 0.9984 - val_loss: 0.1501 - val_acc: 0.9775\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0044 - acc: 0.9986 - val_loss: 0.1431 - val_acc: 0.9791\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0056 - acc: 0.9983 - val_loss: 0.1623 - val_acc: 0.9759\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0058 - acc: 0.9983 - val_loss: 0.1481 - val_acc: 0.9786\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0039 - acc: 0.9986 - val_loss: 0.1560 - val_acc: 0.9769\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0054 - acc: 0.9983 - val_loss: 0.1644 - val_acc: 0.9755\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0047 - acc: 0.9987 - val_loss: 0.1514 - val_acc: 0.9784\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0054 - acc: 0.9985 - val_loss: 0.1551 - val_acc: 0.9780\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0041 - acc: 0.9987 - val_loss: 0.1519 - val_acc: 0.9781\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0053 - acc: 0.9982 - val_loss: 0.1594 - val_acc: 0.9769\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0051 - acc: 0.9984 - val_loss: 0.1577 - val_acc: 0.9775\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0047 - acc: 0.9986 - val_loss: 0.1546 - val_acc: 0.9775\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0033 - acc: 0.9990 - val_loss: 0.1567 - val_acc: 0.9777\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0043 - acc: 0.9986 - val_loss: 0.1473 - val_acc: 0.9794\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0020 - acc: 0.9995 - val_loss: 0.1501 - val_acc: 0.9793\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0045 - acc: 0.9987 - val_loss: 0.1550 - val_acc: 0.9780\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0037 - acc: 0.9987 - val_loss: 0.1430 - val_acc: 0.9794\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0083 - acc: 0.9975 - val_loss: 0.1538 - val_acc: 0.9777\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0072 - acc: 0.9978 - val_loss: 0.1417 - val_acc: 0.9795\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0039 - acc: 0.9988 - val_loss: 0.1488 - val_acc: 0.9784\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0045 - acc: 0.9988 - val_loss: 0.1601 - val_acc: 0.9760\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0046 - acc: 0.9987 - val_loss: 0.1526 - val_acc: 0.9771\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0034 - acc: 0.9989 - val_loss: 0.1580 - val_acc: 0.9771\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0029 - acc: 0.9992 - val_loss: 0.1615 - val_acc: 0.9776\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0043 - acc: 0.9986 - val_loss: 0.1652 - val_acc: 0.9765\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0038 - acc: 0.9988 - val_loss: 0.1549 - val_acc: 0.9784\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0045 - acc: 0.9985 - val_loss: 0.1472 - val_acc: 0.9792\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0025 - acc: 0.9992 - val_loss: 0.1718 - val_acc: 0.9769\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0077 - acc: 0.9979 - val_loss: 0.1674 - val_acc: 0.9739\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0051 - acc: 0.9986 - val_loss: 0.1645 - val_acc: 0.9767\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0037 - acc: 0.9989 - val_loss: 0.1487 - val_acc: 0.9791\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0044 - acc: 0.9986 - val_loss: 0.1581 - val_acc: 0.9778\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0048 - acc: 0.9985 - val_loss: 0.1485 - val_acc: 0.9792\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0034 - acc: 0.9990 - val_loss: 0.1525 - val_acc: 0.9787\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0040 - acc: 0.9987 - val_loss: 0.1537 - val_acc: 0.9778\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0043 - acc: 0.9988 - val_loss: 0.1568 - val_acc: 0.9789\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0033 - acc: 0.9990 - val_loss: 0.1641 - val_acc: 0.9772\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0032 - acc: 0.9991 - val_loss: 0.1637 - val_acc: 0.9776\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0041 - acc: 0.9987 - val_loss: 0.1628 - val_acc: 0.9765\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0071 - acc: 0.9978 - val_loss: 0.1528 - val_acc: 0.9782\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0046 - acc: 0.9986 - val_loss: 0.1551 - val_acc: 0.9785\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0024 - acc: 0.9993 - val_loss: 0.1558 - val_acc: 0.9785\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0039 - acc: 0.9987 - val_loss: 0.1626 - val_acc: 0.9769\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0061 - acc: 0.9984 - val_loss: 0.1847 - val_acc: 0.9729\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0046 - acc: 0.9988 - val_loss: 0.1534 - val_acc: 0.9785\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0035 - acc: 0.9990 - val_loss: 0.1533 - val_acc: 0.9785\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0017 - acc: 0.9994 - val_loss: 0.1577 - val_acc: 0.9791\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0045 - acc: 0.9987 - val_loss: 0.1606 - val_acc: 0.9774\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0026 - acc: 0.9992 - val_loss: 0.1491 - val_acc: 0.9803\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0040 - acc: 0.9988 - val_loss: 0.1645 - val_acc: 0.9781\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0052 - acc: 0.9984 - val_loss: 0.1578 - val_acc: 0.9786\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0039 - acc: 0.9987 - val_loss: 0.1498 - val_acc: 0.9792\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0037 - acc: 0.9990 - val_loss: 0.1620 - val_acc: 0.9777\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0032 - acc: 0.9990 - val_loss: 0.1694 - val_acc: 0.9761\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0046 - acc: 0.9984 - val_loss: 0.1574 - val_acc: 0.9776\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.1508 - val_acc: 0.9794\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0024 - acc: 0.9993 - val_loss: 0.1555 - val_acc: 0.9781\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0078 - acc: 0.9978 - val_loss: 0.1479 - val_acc: 0.9779\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0023 - acc: 0.9993 - val_loss: 0.1588 - val_acc: 0.9766\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0024 - acc: 0.9992 - val_loss: 0.1546 - val_acc: 0.9789\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0041 - acc: 0.9988 - val_loss: 0.1612 - val_acc: 0.9765\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0019 - acc: 0.9994 - val_loss: 0.1588 - val_acc: 0.9781\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.1792 - val_acc: 0.9760\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0052 - acc: 0.9984 - val_loss: 0.1772 - val_acc: 0.9752\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0038 - acc: 0.9986 - val_loss: 0.1806 - val_acc: 0.9756\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0038 - acc: 0.9988 - val_loss: 0.1651 - val_acc: 0.9786\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0024 - acc: 0.9993 - val_loss: 0.1693 - val_acc: 0.9772\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0021 - acc: 0.9993 - val_loss: 0.1672 - val_acc: 0.9776\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0043 - acc: 0.9987 - val_loss: 0.1769 - val_acc: 0.9758\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0075 - acc: 0.9978 - val_loss: 0.1643 - val_acc: 0.9766\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0037 - acc: 0.9989 - val_loss: 0.1508 - val_acc: 0.9792\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0022 - acc: 0.9993 - val_loss: 0.1611 - val_acc: 0.9771\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0045 - acc: 0.9987 - val_loss: 0.1516 - val_acc: 0.9780\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0040 - acc: 0.9987 - val_loss: 0.1554 - val_acc: 0.9778\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0029 - acc: 0.9990 - val_loss: 0.1605 - val_acc: 0.9773\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0029 - acc: 0.9991 - val_loss: 0.1611 - val_acc: 0.9772\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0037 - acc: 0.9989 - val_loss: 0.1657 - val_acc: 0.9773\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0034 - acc: 0.9991 - val_loss: 0.1647 - val_acc: 0.9775\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0036 - acc: 0.9990 - val_loss: 0.1543 - val_acc: 0.9790\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0031 - acc: 0.9990 - val_loss: 0.1489 - val_acc: 0.9786\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0024 - acc: 0.9994 - val_loss: 0.1496 - val_acc: 0.9795\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0045 - acc: 0.9984 - val_loss: 0.1611 - val_acc: 0.9767\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-31a290b07209>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0muniform_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0muniform_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Точность работы на тестовых данных: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "uniform_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "uniform_model.fit(X_train, Y_train, batch_size=200, epochs=100, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.810971815898512e-10 1.3825889766394539e-08 3.4049884334308445e-07\n",
      "  7.291824744015685e-08 2.2276836375567655e-07 8.481625124456826e-11\n",
      "  1.4058863665247778e-12 0.9999986886978149 1.5417113419236017e-10\n",
      "  6.52954895485891e-07]]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from decimal import Decimal\n",
    "import decimal\n",
    "\n",
    "num = 17\n",
    "\n",
    "predict = uniform_model.predict(np.array([X_test[num]]))\n",
    "#print(predict)\n",
    "#scores = uniform_model.evaluate(X_test, Y_test, verbose=0)\n",
    "#print(\"Точность работы на тестовых данных: %.2f%%\" % (scores[1]*100))\n",
    "#print(predict)\n",
    "a = np.array(predict,dtype=np.dtype(decimal.Decimal))\n",
    "print a\n",
    "print a.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQf0/SlQ062L8afgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f859c118610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image = X_test[num].reshape([28,28])\n",
    "plt.imshow(image, cmap=plt.get_cmap('gray_r'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 2.2876 - acc: 0.1377 - val_loss: 2.2673 - val_acc: 0.1707\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 2.2411 - acc: 0.2072 - val_loss: 2.2059 - val_acc: 0.2360\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 2.1624 - acc: 0.2685 - val_loss: 2.1117 - val_acc: 0.2804\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 2.0499 - acc: 0.3091 - val_loss: 1.9881 - val_acc: 0.3217\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 1.9268 - acc: 0.3370 - val_loss: 1.8797 - val_acc: 0.3470\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 1.8340 - acc: 0.3590 - val_loss: 1.8078 - val_acc: 0.3643\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 1.7754 - acc: 0.3768 - val_loss: 1.7632 - val_acc: 0.3801\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 1.7395 - acc: 0.3872 - val_loss: 1.7335 - val_acc: 0.3886\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 1.7148 - acc: 0.3943 - val_loss: 1.7139 - val_acc: 0.3889\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 1.6972 - acc: 0.3974 - val_loss: 1.7048 - val_acc: 0.3910\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 1.6839 - acc: 0.4008 - val_loss: 1.6931 - val_acc: 0.3988\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 1.6732 - acc: 0.4043 - val_loss: 1.6839 - val_acc: 0.3990\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 1.6646 - acc: 0.4040 - val_loss: 1.6789 - val_acc: 0.3991\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 1.6576 - acc: 0.4066 - val_loss: 1.6707 - val_acc: 0.4007\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 1.6511 - acc: 0.4107 - val_loss: 1.6708 - val_acc: 0.4045\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 1.6462 - acc: 0.4098 - val_loss: 1.6802 - val_acc: 0.4042\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 1.6415 - acc: 0.4111 - val_loss: 1.6615 - val_acc: 0.4058\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 1.6382 - acc: 0.4117 - val_loss: 1.6608 - val_acc: 0.4019\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 1.6341 - acc: 0.4118 - val_loss: 1.6747 - val_acc: 0.4035\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 1.6312 - acc: 0.4135 - val_loss: 1.6552 - val_acc: 0.4042\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 1.6281 - acc: 0.4131 - val_loss: 1.6684 - val_acc: 0.4010\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 1.6259 - acc: 0.4151 - val_loss: 1.6483 - val_acc: 0.4081\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 1.6235 - acc: 0.4140 - val_loss: 1.6500 - val_acc: 0.4080\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 1.6216 - acc: 0.4149 - val_loss: 1.6479 - val_acc: 0.4079\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 1.6196 - acc: 0.4154 - val_loss: 1.6521 - val_acc: 0.4063\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 1.6180 - acc: 0.4148 - val_loss: 1.6559 - val_acc: 0.4112\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 1.6156 - acc: 0.4162 - val_loss: 1.6558 - val_acc: 0.4051\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 1.6152 - acc: 0.4163 - val_loss: 1.6410 - val_acc: 0.4101\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 1.6128 - acc: 0.4168 - val_loss: 1.6523 - val_acc: 0.4084\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 1.6126 - acc: 0.4161 - val_loss: 1.6478 - val_acc: 0.4112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12a361b10>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glorot_model = create_model(\"glorot_normal\")\n",
    "glorot_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "glorot_model.fit(X_train_reshaped, Y_train_cat, batch_size=64, nb_epoch=30, verbose=1, validation_data=(X_test_reshaped, Y_test_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
